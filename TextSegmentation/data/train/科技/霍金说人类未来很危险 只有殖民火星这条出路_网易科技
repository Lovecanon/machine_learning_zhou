霍金说人类未来很危险 只有殖民火星这条出路_网易科技
霍金又提世界末日了，真不“正能量”。
你会相信，人类离灭亡最近的时刻，是下一个百年吗？信不信由你，至少霍金信了。在 BBC 近期的采访中，史蒂芬・霍金警告道：由于科学和技术的快速发展，在未来的一百年里，人类将时刻处在自我毁灭的危险之中。作为著名物理学家霍金认为，迅猛发展的科技在为我们带来各种福利的同时，也创造了“新的出问题的方式”，这带来的高风险是人类很难控制的。他尤其强调核战争、全球气候变暖和基因工程病毒的危险性，表示这三者很可能就是我们自创末日的预兆。这并非是霍金第一次提到世界末日。早在 2014 年，霍金就曾提醒我们注意人工智能的威胁。他认为一旦人工智能跨过了与人类智慧相同的“奇点”（ Singular Point ），我们可能会面临“智慧爆炸”（intelligence explosion），届时，人工智能在智慧上超越我们，而且将比人类超过蜗牛的程度还大。这对人类产生的影响，要么就是最好的，要么就是最糟糕的。它既可能让人类永生，也可能让人类毁灭。
 
不过，霍金还在采访中表示，他是一个彻底的乐观主义者。他相信人类终有办法克服面临的问题。对此霍金给出的建议是：殖民火星。他觉得这个方法可以保证在最坏的情况降临时，还能有一部分人类在其他星球的“避风港”中继续生存下去。但是，在接下来的一个世纪，这恐怕很难成为现实。而霍金认为，尽管现在发生全球性灾难的几率很低，但它会随着时间的推移增加，并在接下来的一千年到一万年之间变成 100%。而人类正在没有安全网的情况下飞速地前进着，这让下个世纪变成了“最危险的 100年”。所以霍金说：“未来的 100 年生死攸关，所以我们必须非常小心。”

 本文来源：好奇心日报  
责任编辑：王一粟_NT4014