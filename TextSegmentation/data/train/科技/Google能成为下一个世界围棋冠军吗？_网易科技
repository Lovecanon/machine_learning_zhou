Google能成为下一个世界围棋冠军吗？_网易科技

刘佳 任绍敏有着2500多年历史的围棋，一直被视作计算机最难以攻克的大众棋类。但现在，这一人工智能研究领域的“拦路虎”，开始遭遇强劲挑战。1月28日，GoogleDeepMind团队宣布，他们研发的人工智能（ArtificialIntelligence，下称“AI”）程序AlphaGo，在没有任何让子的情况下以5∶0击败了欧洲围棋冠军职业围棋二段樊麾，同时也击败了目前最好的围棋程序中99.8%的对手。果壳网新浪微博称：“围棋，人类已经下不过谷歌的AI了！”多年以后，当人类仰视AI的智慧时，准会想起谷歌推动黑白子的无形的手。围棋九段、第二届百灵杯世界冠军柯洁转发了上述微博，并评论说：“震惊！！赞！虽说看棋谱感觉水平有限……但可怕的是这还不是完全体，它是可以学习进化的……”AlphaGo的下一个挑战将是世界顶级围棋选手之一李世石，这场对战将在今年3月进行。李世石是围棋九段高手，也是近10年来获得世界第一头衔最多的棋手，Google为此提供了100万美元作为奖金。为什么围棋难以攻克？1997年5月，象棋冠军加里・卡斯帕罗夫被IBM“深蓝”击败。今年3月，相似的历史还会重演吗？“对于更加智能和灵活、具备与人类类似解决问题能力算法的开发工作而言，游戏无疑是一个绝佳的试验场。”Google在官方博客中这样写道。历史上，电脑最早掌握的第一款经典游戏是井字游戏，这是1952年一位博士在读生的研究项目；随后是1994年电脑程序Chinook成功挑战西洋跳棋游戏；3年后，IBM深蓝超级计算机在国际象棋比赛中战胜世界冠军加里・卡斯帕罗夫。除了棋盘游戏外，IBM的Watson系统在2011年成功挑战老牌智力竞赛节目Jeopardy游戏一战成名；2014年，Google自己编写的算法，学会了仅需输入初始像素信息就能玩几十种Atari游戏。但此前，有一项游戏仍然是人类代表着顶尖水平，那就是围棋。围棋虽然看上去规则简单，却因为精妙而富有思想深度，几个世纪来都牢牢抓住了人们的想象力。Google介绍说，围棋的搜索空间是漫无边际的――比围棋棋盘要大1个古戈尔（数量级单位，10的100次方，甚至比宇宙中的原子数量还要多）。因此，传统的“强力”人工智能方法也就是“为所有可能的步数建立搜索树”，在围棋游戏中根本无法实现。今年1月10日，卡耐基梅隆大学机器人系博士、Facebook人工智能组研究员田渊栋曾在知乎中作答称，“围棋难的地方在于它的估值函数非常不平滑，差一个子盘面就可能天翻地覆，同时状态空间大，也没有全局的结构。这两点加起来，迫使目前计算机只能用穷举法并且因此进展缓慢。”目前，Facebook的智能围棋darkforest最新的darkfmcts3在KGS围棋服务器上达到了5d，赢了一局Zen，输了一局给DolBaram，被让四子与一位韩国的职业六段一胜一负。“现在的深度学习能在大量对局中找到这样的一些规律，但仍然没有人脑厉害。这一方面说明我们现在算法的局限性，另一方面它还有巨大的发展空间。”他说。人工智能击败职业顶尖棋手真的快了吗？知名少儿对弈平台新博围棋老总陈劲松在朋友圈评论说：“三个月以后，Deeplearning也许可以打败李世石，那也只不过是围棋高手队伍里面多了一个小伙伴而已，它学会了大家所有的招数。它同时还在等待学习你们发明的新的招数。”职业二段棋手、围棋资深教练刘轶一对《第一财经日报》称，不用担心，不会那么容易。不过他所在的朋友圈里，围棋职业棋手们众说纷纭，有些认为不可能，有些认为指日可待了，还有声音是“人类快被自己灭绝了”。击败欧洲围棋冠军那么，人工智能程序AlphaGo是如何击败围棋高手的？GoogleAlphaGo的研究者DavidSilver说，AlphaGo系统的关键是，将围棋巨大无比的搜索空间压缩到可控的范围之内。而为了达到这一目的，AlphaGo系统将最先进的蒙特卡洛树状搜索技术与两个深层神经网络相结合，每个深层神经网络均包含许多层，每层又包含数以百万计的神经元一样的连接。在AlphaGo两种不同的神经网络中，“策略网络（policynetwork）”的作用是预测下一步，并用来将搜索范围缩小至最有可能硬起的那些步骤。另一个神经网络“价值网络（valuenetwork）”则是用来减少搜索树的深度，每走一步估算一次获胜方，而不是搜索所有结束棋局的途径。上述方法使得AlphaGo的搜索方式相比之前的方法更人性化。例如，深蓝采用强力方法搜索的棋子位置要比AlphaGo多数千倍。而AlphaGo则相反，它通过想象下完剩余棋局来对下一步进行预判，如此多次反复。在上述模拟游戏中，策略网络提出下一步的智能建议，而价值网络则对走过的每个位置进行评估。具体而言，Google首先采用围棋专业棋手的3000万步下法对价值网络进行训练，直到该网络对人类下法预测准确率达到57%（AlphaGo之前的纪录是44%）。但AlphaGo的目标是击败水平最高的人类棋手，而不仅仅是模仿他们。为了做到这一点，AlphaGo学会自己发现新策略，通过自身两个神经网络之间成千上万的对弈，采用被称为强化学习的试错法逐步进行改善。这种方法提高了策略网络的效率，以至于最原始的神经网络（即其中不包含任何树状搜索）可以击败最尖端、构建有巨大无比的搜索树的围棋软件。这些策略网络又反过来对价值网络进行训练，采用的还是从自我对弈强化学习的方法。这些价值网络可以对围棋的任何位置进行评估并预测获胜方，而人们过去曾认为这个问题太过困难，根本无法实现。实现上述所有设想的前提是，计算机要超级强大。Google称，这一过程大量使用了Google云平台，使得人工智能和机器学习研究人员得以随时灵活地获得计算、存储和联网能力。此外，采用数据流图形（如TensorFlow）、用于数值计算的开房源库使研究人员得以对多个CPU或GPU的深度学习算法的计算需求进行高效利用。AlphaGo到底有多强大？为了回答这个问题，Google在AlphaGo和人工智能研究领域最前沿的其他顶级围棋软件如CrazyStone、Zen和Pachi之间进行了一次比赛。AlphaGo在总计495局中只输了一局，胜率是99.8%。
 
AlphaGo甚至在每局开局让对方四步的情况下对阵CrazyStone、Zen和Pachi，胜率分别达到了77%、86%和99%。如果在今年3月的对战中，AlphaGo战胜李世石，是否意味着人工智能已经超过人类?或许还不能如此断言。但新成立的非营利性组织OpenAI的AI研究者IlyaSutskever认为，从技术的角度说，这个研究对AI具有纪念碑式的贡献。在棋类游戏之外，这场对决也将引发更多的思考――那些人们曾经以为人工智能不可能完成的脑力挑战，是否都将被一一打破？未来人类是否会被人工智能所取代？

 本文来源：第一财经日报  
责任编辑：李德雄_NT2021